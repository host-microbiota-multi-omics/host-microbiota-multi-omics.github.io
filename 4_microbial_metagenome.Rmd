# Microbial metagenome {-}

Microbial metagenomic assembly and binning are key steps in reconstructing the genomes of microorganisms present 
in complex communities. This chapter describes the Snakemake rules that perform metagenomic assembly using MEGAHIT, 
create Bowtie2 indices for the assemblies, map reads back to the assemblies, calculate contig coverage, and bin contigs 
into metagenome-assembled genomes (MAGs) using multiple binning tools (MetaBAT2, MaxBin2, SemiBin2). Finally, it covers 
the refinement of bins using Binette to produce high-quality MAGs for downstream analyses.

## Assembly

This rule performs metagenomic assembly using MEGAHIT. For each defined assembly group, 
it gathers the metagenomic paired-end reads (R1 and R2) from one or more samples, combines them, 
and runs MEGAHIT to reconstruct longer contiguous sequences (contigs) from the short reads. This can be a 
single-sample assembly or a co-assembly of multiple related samples, depending on how ASSEMBLY_TO_SAMPLES is defined. 
The result is a FASTA file containing assembled contigs that represent fragments of microbial genomes present in the 
samples, filtered to retain only contigs above a certain minimum length to focus on more reliable sequences.

The rule ensures that the output directory is clean before each run, uses multiple threads and dynamically allocated 
memory to handle larger datasets, and then standardizes the output by renaming MEGAHIT's final contig file to a consistent 
path and filename. This assembled contig file becomes the basis for downstream cataloging steps such as binning, annotation, 
and construction of metagenome-assembled genomes (MAGs) in the host-microbiota multi-omics workflow.

```{sh eval=FALSE}
rule assembly:
    input:
        r1=lambda wildcards: [f"{OUTPUT_DIR}/preprocessing/final/{sample}_1.fq.gz" for sample in ASSEMBLY_TO_SAMPLES[wildcards.assembly]],
        r2=lambda wildcards: [f"{OUTPUT_DIR}/preprocessing/final/{sample}_2.fq.gz" for sample in ASSEMBLY_TO_SAMPLES[wildcards.assembly]]
    shell:
        """
        rm -rf {params.outputdir}

        # Convert input list to a comma-separated string
        R1_FILES=$(echo {input.r1} | tr ' ' ',')
        R2_FILES=$(echo {input.r2} | tr ' ' ',')

        megahit \
            -t {threads} \
            --verbose \
            --min-contig-len 1500 \
            -1 $R1_FILES -2 $R2_FILES \
            -o {params.outputdir}
        mv {params.outputdir}/final.contigs.fa {output}
        """

```

## Assembly index

This rule creates a Bowtie2 index for each metagenomic assembly generated in the previous step. 
It takes the assembled contigs (the reconstructed metagenome) and runs bowtie2-build to generate the 
indexing files required for efficient read alignment. Indexing metagenomic assemblies is essential for 
downstream processes such as read recruitment, contig coverage estimation, binning, and quality assessment 
of assembled genomes.

The rule ensures the index is stored alongside the assembly under a consistent naming scheme, allowing later 
rules to easily locate it. It uses modest computational resources, since indexing contigs is generally 
lightweight compared to assembly, and loads the correct Bowtie2 module to guarantee reproducibility. This step 
prepares the assembled contigs to be used as a searchable reference in subsequent cataloging analyses.

```{sh eval=FALSE}
rule assembly_index:
    input:
        f"{OUTPUT_DIR}/cataloging/megahit/{{assembly}}/{{assembly}}.fna"
    output:
        index=f"{OUTPUT_DIR}/cataloging/megahit/{{assembly}}/{{assembly}}.rev.2.bt2"
    params:
        bowtie2_module={BOWTIE2_MODULE},
        basename=f"{OUTPUT_DIR}/cataloging/megahit/{{assembly}}/{{assembly}}"
    shell:
        """
        bowtie2-build {input} {params.basename}
        """
```

## Assembly mapping

This rule maps each sample's metagenomic reads back to a specific metagenomic assembly using Bowtie2. 
By aligning the cleaned, host-filtered reads to the assembled contigs, the workflow can quantify how much 
support each contig has across samples—information that is essential for downstream steps such as binning, 
abundance estimation, contamination checking, and cross-sample comparative analyses. The rule uses the Bowtie2 
index generated for the assembly and the final FASTQ files produced during host–microbiota read separation.

The alignment output is directly converted to a sorted BAM file through samtools, ensuring the result is 
immediately usable for coverage calculation or other depth-based analyses. With multi-threading support and 
adaptive resource allocation, the rule efficiently handles both small and large datasets. This mapping step 
links reads back to the assembly, turning raw contigs into quantitatively interpretable components of the 
microbial community.

```{sh eval=FALSE}
rule assembly_map:
    input:
        index=lambda wildcards: f"{OUTPUT_DIR}/cataloging/megahit/{wildcards.assembly}/{wildcards.assembly}.rev.2.bt2",
        r1=lambda wildcards: f"{OUTPUT_DIR}/preprocessing/final/{wildcards.sample}_1.fq.gz",
        r2=lambda wildcards: f"{OUTPUT_DIR}/preprocessing/final/{wildcards.sample}_2.fq.gz"
    output:
        f"{OUTPUT_DIR}/cataloging/bowtie2/{{assembly}}/{{sample}}.bam"
    params:
        basename=lambda wildcards: f"{OUTPUT_DIR}/cataloging/megahit/{wildcards.assembly}/{wildcards.assembly}"
    shell:
        """
        bowtie2 -x {params.basename} -1 {input.r1} -2 {input.r2} | samtools view -bS - | samtools sort -o {output}
        """
```

## Assembly map depth

This rule computes per-contig read depth across all samples associated with a given assembly. 
It takes the set of BAM files produced by mapping each sample's metagenomic reads back to the assembly 
and uses `jgi_summarize_bam_contig_depths` (from MetaBAT2) to generate a depth table. This table reports 
how many reads align to each contig in each sample—information that is essential for binning tools, which 
rely on differential coverage patterns to group contigs into metagenome-assembled genomes (MAGs).

The rule outputs two versions of the depth file: the full MetaBAT2-compatible depth matrix and a simplified 
depth file formatted for MaxBin2. These coverage profiles are a key input for downstream binning workflows, 
as they allow algorithms to distinguish which contigs likely originate from the same genome.

```{sh eval=FALSE}
rule assembly_map_depth:
    input:
        lambda wildcards: [
            f"{OUTPUT_DIR}/cataloging/bowtie2/{wildcards.assembly}/{sample}.bam"
            for sample in ASSEMBLY_TO_SAMPLES[wildcards.assembly]
        ]
    output:
        metabat2=f"{OUTPUT_DIR}/cataloging/bowtie2/{{assembly}}_metabat.depth",
        maxbin2=f"{OUTPUT_DIR}/cataloging/bowtie2/{{assembly}}_maxbin.depth"
    shell:
        """
        jgi_summarize_bam_contig_depths --outputDepth {output.metabat2} {input}
        cut -f1,3 {output.metabat2} | tail -n+2 > {output.maxbin2}
        """
```

## Binning

MetaBAT2, MaxBin2, and SemiBin2 are complementary metagenomic binning tools that take assembled contigs 
and coverage information and attempt to cluster contigs into metagenome-assembled genomes (MAGs). Because 
no single algorithm is perfect for all datasets, using multiple binners increases the robustness and completeness 
of the final genome catalog. Each tool uses different combinations of signals—coverage patterns across samples, 
sequence composition, and marker-gene information—to infer which contigs originate from the same microbial genome. 
Running all three methods, then harmonizing the outputs, provides a stronger basis for downstream bin refinement 
and MAG quality filtering.

### MetaBat2

MetaBAT2 clusters contigs based mainly on differential coverage across samples and tetranucleotide frequency, 
producing a TSV mapping contigs to bins. It is fast, widely used, and effective when multiple samples provide 
rich coverage variation.

```{sh eval=FALSE}
rule metabat2:
    input:
        assembly=f"{OUTPUT_DIR}/cataloging/megahit/{{assembly}}/{{assembly}}.fna",
        depth=f"{OUTPUT_DIR}/cataloging/bowtie2/{{assembly}}_metabat.depth"
    output:
        f"{OUTPUT_DIR}/cataloging/metabat2/{{assembly}}/{{assembly}}.tsv"
    shell:
        """
        metabat2 -i {input.assembly} -a {input.depth} -o {output} -m 1500 --saveCls --noBinOut
        """
```

### MaxBin2

MaxBin2 uses marker-gene detection, sequence composition, and abundance patterns to group contigs. It tends to 
perform well for genomes with typical marker sets, and the workflow includes logic to skip running it on very small 
assemblies where meaningful binning is unlikely.

```{sh eval=FALSE}
rule maxbin2:
    input:
        assembly=f"{OUTPUT_DIR}/cataloging/megahit/{{assembly}}/{{assembly}}.fna",
        depth=f"{OUTPUT_DIR}/cataloging/bowtie2/{{assembly}}_maxbin.depth"
    output:
        f"{OUTPUT_DIR}/cataloging/maxbin2/{{assembly}}/{{assembly}}.summary"
    params:
        basename=f"{OUTPUT_DIR}/cataloging/maxbin2/{{assembly}}/{{assembly}}",
        assembly_size_mb=lambda wildcards, input: int(Path(input.assembly).stat().st_size / (1024*1024))
    shell:
        """
        if (( {params.assembly_size_mb} < 10 )); then
            echo "Assembly is smaller than 10 MB, skipping maxbin2..."
            touch {output}
        else
            MODULEPATH=/opt/shared_software/shared_envmodules/modules:$MODULEPATH \
            module load {params.maxbin2_module} {params.hmmer_module}
            rm -rf {params.basename}*
            run_MaxBin.pl -contig {input.assembly} -abund {input.depth} -max_iteration 10 -out {params.basename} -min_contig_length 1500
        fi
        """
```

### SemiBin2

SemiBin2 performs machine-learning–based genome binning using the assembly together with all sample-specific BAM files. 
It integrates sequence composition, depth information, and neural-network–derived embeddings to cluster contigs into 
high-quality genome bins. This rule runs SemiBin2 in its “single easy bin” mode, which automates preprocessing steps 
such as marker gene detection and coverage calculation.

```{sh eval=FALSE}
rule semibin2:
    input:
        assembly=f"{OUTPUT_DIR}/cataloging/megahit/{{assembly}}/{{assembly}}.fna",
        bam=lambda wildcards: [
            f"{OUTPUT_DIR}/cataloging/bowtie2/{wildcards.assembly}/{sample}.bam"
            for sample in ASSEMBLY_TO_SAMPLES[wildcards.assembly]
            ]
    output:
        f"{OUTPUT_DIR}/cataloging/semibin2/{{assembly}}/contig_bins.tsv"
    params:
        semibin2_module={SEMIBIN2_MODULE},
        hmmer_module={HMMER_MODULE},
        bedtools_module={BEDTOOLS_MODULE},
        outdir=f"{OUTPUT_DIR}/cataloging/semibin2/{{assembly}}",
        assembly_size_mb=lambda wildcards, input: int(Path(input.assembly).stat().st_size / (1024*1024))
    threads: 8
    resources:
        mem_mb=lambda wildcards, input, attempt: min(1000*1024,max(8*1024, int(input.size_mb * 30) * 2 ** (attempt - 1))),
        runtime=lambda wildcards, input, attempt: min(20000,max(15, int(input.size_mb / 2) * 2 ** (attempt - 1)))
    message: "Binning contigs from assembly {wildcards.assembly} using semibin2..."
    shell:
        """
        if (( {params.assembly_size_mb} < 10 )); then
            echo "Assembly is smaller than 10 MB, skipping semibin2..."
            touch {output}
        else
            module load {params.semibin2_module} {params.bedtools_module} {params.hmmer_module}
            SemiBin2 single_easy_bin -i {input.assembly} -b {input.bam} -o {params.outdir} -m 1500 -t {threads} --compression none
        fi
        """
```

This rule simply reformats its existing contig_bins.tsv output into a consistent table for integration with the 
other binners' results.

```{sh eval=FALSE}
rule semibin2_table:
    input:
        f"{OUTPUT_DIR}/cataloging/semibin2/{{assembly}}/contig_bins.tsv"
    output:
        f"{OUTPUT_DIR}/cataloging/semibin2/{{assembly}}/{{assembly}}.tsv"
    params:
        fastadir=f"{OUTPUT_DIR}/cataloging/semibin2/{{assembly}}/output_bins"
    shell:
        """
        tail -n +2 {input} > {output}
        """
```

## Bin refinement

This checkpoint performs bin refinement and quality assessment by combining the results from the three binners 
(MetaBAT2, MaxBin2, SemiBin2) using binette. It takes each binner's contig-to-bin TSV plus the original 
assembly FASTA and feeds only the non-empty TSV files into binette. Binette then reconciles overlapping or 
conflicting bin assignments across tools, refines bin boundaries, and evaluates the resulting bins’ completeness 
and contamination (via CheckM2), producing a final table of bins with quality metrics. This step is where the 
workflow turns three separate binning runs into a unified, curated set of metagenome-assembled genomes.

The shell logic first checks which of the individual binner outputs actually contain data (for example, 
small assemblies may have caused some tools to be skipped), builds a list of valid TSV files, and aborts with 
an error if none are available. If at least one binner produced bins, binette is run with those inputs and the 
contig FASTA, writing its results into a dedicated output directory and summarizing the final refined bins in 
final_bins_quality_reports.tsv.

```{sh eval=FALSE}
checkpoint binette:
    input:
        metabat2=f"{OUTPUT_DIR}/cataloging/metabat2/{{assembly}}/{{assembly}}.tsv",
        maxbin2=f"{OUTPUT_DIR}/cataloging/maxbin2/{{assembly}}/{{assembly}}.tsv",
        semibin2=f"{OUTPUT_DIR}/cataloging/semibin2/{{assembly}}/{{assembly}}.tsv",
        fasta=f"{OUTPUT_DIR}/cataloging/megahit/{{assembly}}/{{assembly}}.fna"
    output:
        f"{OUTPUT_DIR}/cataloging/binette/{{assembly}}/final_bins_quality_reports.tsv"
    params:
        outdir=f"{OUTPUT_DIR}/cataloging/binette/{{assembly}}"
    shell:
        """
        # Define input files
        METABAT2="{input.metabat2}"
        MAXBIN2="{input.maxbin2}"
        SEMIBIN2="{input.semibin2}"

        # Remove empty input files from the list
        VALID_TSV_FILES=""
        if [ -s "$METABAT2" ]; then
            VALID_TSV_FILES="$VALID_TSV_FILES $METABAT2"
        fi
        if [ -s "$MAXBIN2" ]; then
            VALID_TSV_FILES="$VALID_TSV_FILES $MAXBIN2"
        fi
        if [ -s "$SEMIBIN2" ]; then
            VALID_TSV_FILES="$VALID_TSV_FILES $SEMIBIN2"
        fi

        # Ensure at least one valid TSV file exists
        if [ -z "$VALID_TSV_FILES" ]; then
            echo "Error: No valid TSV input files for binette." >&2
            exit 1
        fi

        # Run binette only with non-empty TSV files
        binette --contig2bin_tables $VALID_TSV_FILES \
                --contigs {input.fasta} \
                --outdir {params.outdir} \
                --checkm2_db {params.checkm_db} \
                --threads {threads}
        """
```

## Rename bins

This code connects the bin refinement results from Binette to the final, nicely named bin FASTA files 
that the user will see. The helper function get_bin_fna_sep uses the Binette checkpoint output to (internally) 
regenerate the list of bin IDs that exist for a given assembly. Conceptually, it tells Snakemake: “for this 
assembly, there are bins with these IDs, and their sequences live in final_bins/bin_<bin_id>.fa.” That way,
the workflow can dynamically adapt to however many bins Binette produced without hard-coding bin names or counts.

The rename_bins rule then takes each of those Binette bin FASTA files and runs a small Python script (rename_bins.py) 
to copy/rename them into a standardized, final location: final/{assembly}/{assembly}_bin_{bin_id}.fa. This step cleans 
up Binette’s internal naming scheme and produces consistently named MAG files that are easier to track, share, and feed 
into downstream analyses such as annotation or taxonomic classification.

```{sh eval=FALSE}

# Regenerate the bin_id wildcard based on the checkpoint results
def get_bin_fna_sep(wildcards):
    checkpoint_output = checkpoints.binette.get(**wildcards).output[0]
    cluster_ids = get_bin_ids_from_tsv(checkpoint_output)
    return f"{OUTPUT_DIR}/cataloging/binette/{{assembly}}/final_bins/bin_{wildcards.bin_id}.fa"

rule rename_bins:
    input:
        lambda wildcards: get_bin_fna_sep(wildcards)
    output:
        f"{OUTPUT_DIR}/cataloging/final/{{assembly}}/{{assembly}}_bin_{{bin_id}}.fa"
    params:
        package_dir={PACKAGE_DIR}
    shell:
        """
        python {params.package_dir}/workflow/scripts/rename_bins.py {wildcards.assembly} {input} {output}
        """
```

## Functional annotation

```{sh eval=FALSE}
```

## Dereplication